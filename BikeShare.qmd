---
title: "BikeShare"
format: html
---

```{r}
#Libraries
library(tidyverse)
library(ggplot2)
library(tidymodels)
library(vroom)
library(dplyr)
library(GGally)
library(patchwork)
library(glmnet)
```

```{r}
#importing data
trainData <- vroom("/Users/Ben/Library/Mobile Documents/com~apple~CloudDocs/BYU/STAT 348/Git/KaggleBikeShare/train.csv") %>%
  select(-casual, -registered) %>% #getting ride of casual and registered count
  mutate(count = log1p(count)) #log transformation on count response

testData <- vroom('/Users/Ben/Library/Mobile Documents/com~apple~CloudDocs/BYU/STAT 348/Git/KaggleBikeShare/test.csv')
```

```{r}
#wrangling recipe
bike_recipe <- recipe(count ~ ., data = trainData) %>%
  step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%  #factoring weather
  step_mutate(weather = factor(weather, levels = c(1,2,3))) %>% 
  step_time(datetime, features = c("hour"),keep_original_cols = F) %>% #select hour
  step_mutate(season = factor(season, 
                              levels = c(1,2,3,4), #factoring season
                              labels = c("spring","summer","fall","winter"))) %>% 
  step_dummy(all_nominal_predictors()) %>% #make dummy variables
  step_normalize(all_numeric_predictors()) # Make mean 0, sd=1


prepped_recipe <- prep(bike_recipe)
```

```{r}
#baking data
baked_train <- bake(prepped_recipe, new_data = trainData)
baked_test <- bake(prepped_recipe, new_data = testData)
```

```{r}
#grid of values to tune
grid_of_tune_params <- grid_regular(penalty(),
                                    mixture(),
                                    levels = 5)

#split data for cross-validation
K <- 10
folds <- vfold_cv(trainData, v = K, repeats = 1)
```

```{r}
#regression tree model

my_model <-decision_tree(tree_depth = tune(),
                         cost_complexity = tune(),
                         min_n = tune()) %>% 
  set_engine('rpart') %>% 
  set_mode('regression')
```

```{r}
#regression tree workflow

tree_wf <-
  
```

```{r}
#final wf
final_wf <-
  preg_wf %>% 
  finalize_workflow(bestTune) %>% 
  fit(data = trainData)

#predict 
submission <- final_wf %>% 
  predict(new_data = testData) %>% 
  mutate(count = pmax(0, round(expm1(.pred)))) %>%
  bind_cols(testData %>% select(datetime)) %>%
  select(datetime, count) %>%
  mutate(datetime = format(as.POSIXct(datetime, tz = "UTC"), "%Y-%m-%d %H:%M:%S"))
```

```{r}
#writing output for kaggle
vroom_write(submission, "submission_cv_tuning.csv", delim = ',')
```

```{r}
#legacy code

#penalized regression model
preg_model <- linear_reg(penalty=tune(), 
                         mixture=tune()) %>%
  set_engine("glmnet") 

#workflow
preg_wf <- workflow() %>%
  add_recipe(bike_recipe) %>%
  add_model(preg_model)

#run CV
CV_results <- preg_wf %>% 
  tune_grid(resamples = folds,
            grid = grid_of_tune_params,
            metrics = metric_set(rmse, mae))

#plot results
collect_metrics(CV_results) %>% 
  filter(.metric == 'rmse') %>% 
  ggplot(data=., aes(x=penalty, y=mean, color = factor(mixture))) +
  geom_line()

#find best funing param
bestTune <- CV_results %>% 
  select_best(metric='rmse')
```
